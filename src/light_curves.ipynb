{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP \n",
    "\n",
    "### To run on GPU set \"CUDA_VISIBLE_DEVICES\" to the GPU number [0,1,2,etc] you wish to use.  To run on CPU, leave blank as \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "from pandas import read_csv, DataFrame\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\")) #this line expands notebook display horizontally\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\" #Comment this line out if you want all GPUS (2 hehe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcs to create model and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, 8, input_shape = (3664, 1), activation = 'relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(64, 8,  activation = 'relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(128, 8, activation = 'relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv1D(256, 8,  activation = 'relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, activation = 'softmax'))\n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, Y_train, X_val, Y_val):\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr = 1e-4), metrics = ['accuracy'])\n",
    "    model.fit(X_train, Y_train, batch_size = 16, validation_data = (X_val, Y_val), epochs = 4)\n",
    "\n",
    "    pred = model.predict(X_val)\n",
    "    print(roc_auc_score(Y_val[:,0], pred[:,0]),roc_auc_score(Y_val[:,1], pred[:,1]), roc_auc_score(Y_val[:,2], pred[:,2]))\n",
    "    return roc_auc_score(Y_val[:,0], pred[:,0]),roc_auc_score(Y_val[:,1], pred[:,1]), roc_auc_score(Y_val[:,2], pred[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown\n",
      "3404 3423 3167\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('../data/simulations.csv')\n",
    "prec = []\n",
    "eci = []\n",
    "spin = []\n",
    "\n",
    "for column in df:\n",
    "    if 'prec' in column:\n",
    "        prec.append(df[column])\n",
    "    elif 'spin' in column:\n",
    "        spin.append(df[column])\n",
    "    elif 'eci' in column:\n",
    "        eci.append(df[column])\n",
    "    else:\n",
    "        print(\"Unknown\")\n",
    "print(len(prec), len(spin), len(eci))\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_val = []\n",
    "Y_val = []\n",
    "\n",
    "for j in prec:\n",
    "    Y_train.append(0)\n",
    "X_train += prec\n",
    "\n",
    "for j in eci:\n",
    "    Y_train.append(1)\n",
    "X_train += eci\n",
    "\n",
    "for j in spin:\n",
    "    Y_train.append(2)\n",
    "X_train += spin\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "X_train = np.expand_dims(X_train, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified 10-fold (results are mean AUROC and std AUROC for each class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1/10...\n",
      "Train on 8993 samples, validate on 1001 samples\n",
      "Epoch 1/4\n",
      "8993/8993 [==============================] - 132s 15ms/step - loss: 0.3022 - acc: 0.9218 - val_loss: 0.1293 - val_acc: 0.9600\n",
      "Epoch 2/4\n",
      "8993/8993 [==============================] - 134s 15ms/step - loss: 0.1397 - acc: 0.9559 - val_loss: 0.1898 - val_acc: 0.9520\n",
      "Epoch 3/4\n",
      "8993/8993 [==============================] - 133s 15ms/step - loss: 0.1193 - acc: 0.9616 - val_loss: 0.1991 - val_acc: 0.9451\n",
      "Epoch 4/4\n",
      "8993/8993 [==============================] - 136s 15ms/step - loss: 0.1046 - acc: 0.9699 - val_loss: 0.0854 - val_acc: 0.9740\n",
      "0.9966453390207056 0.9998708653863891 0.9944260813313601\n",
      "Training on fold 2/10...\n",
      "Train on 8993 samples, validate on 1001 samples\n",
      "Epoch 1/4\n",
      "8993/8993 [==============================] - 141s 16ms/step - loss: 0.3058 - acc: 0.9214 - val_loss: 0.1128 - val_acc: 0.9610\n",
      "Epoch 2/4\n",
      "8993/8993 [==============================] - 138s 15ms/step - loss: 0.1734 - acc: 0.9521 - val_loss: 0.0494 - val_acc: 0.9820\n",
      "Epoch 3/4\n",
      "8993/8993 [==============================] - 128s 14ms/step - loss: 0.1340 - acc: 0.9624 - val_loss: 0.0713 - val_acc: 0.9730\n",
      "Epoch 4/4\n",
      "8993/8993 [==============================] - 133s 15ms/step - loss: 0.0854 - acc: 0.9731 - val_loss: 0.1167 - val_acc: 0.9770\n",
      "0.9971740869101573 0.9999907760990279 0.9915815218836123\n",
      "Training on fold 3/10...\n",
      "Train on 8993 samples, validate on 1001 samples\n",
      "Epoch 1/4\n",
      "8993/8993 [==============================] - 136s 15ms/step - loss: 0.2695 - acc: 0.9195 - val_loss: 0.1205 - val_acc: 0.9530\n",
      "Epoch 2/4\n",
      "8993/8993 [==============================] - 129s 14ms/step - loss: 0.1543 - acc: 0.9456 - val_loss: 0.1001 - val_acc: 0.9690\n",
      "Epoch 3/4\n",
      "8993/8993 [==============================] - 129s 14ms/step - loss: 0.1186 - acc: 0.9602 - val_loss: 0.1050 - val_acc: 0.9650\n",
      "Epoch 4/4\n",
      "8993/8993 [==============================] - 128s 14ms/step - loss: 0.0844 - acc: 0.9746 - val_loss: 0.1389 - val_acc: 0.9520\n",
      "0.9908379987558874 0.9998431936834725 0.9922239846872314\n",
      "Training on fold 4/10...\n",
      "Train on 8994 samples, validate on 1000 samples\n",
      "Epoch 1/4\n",
      "8994/8994 [==============================] - 123s 14ms/step - loss: 0.3080 - acc: 0.9152 - val_loss: 0.0804 - val_acc: 0.9730\n",
      "Epoch 2/4\n",
      "8994/8994 [==============================] - 122s 14ms/step - loss: 0.1479 - acc: 0.9527 - val_loss: 0.0897 - val_acc: 0.9700\n",
      "Epoch 3/4\n",
      "8994/8994 [==============================] - 131s 15ms/step - loss: 0.1046 - acc: 0.9649 - val_loss: 0.0701 - val_acc: 0.9750\n",
      "Epoch 4/4\n",
      "8994/8994 [==============================] - 131s 15ms/step - loss: 0.0858 - acc: 0.9730 - val_loss: 0.1641 - val_acc: 0.9540\n",
      "0.9964711484120169 0.9999538129702417 0.9879841447590608\n",
      "Training on fold 5/10...\n",
      "Train on 8995 samples, validate on 999 samples\n",
      "Epoch 1/4\n",
      "8995/8995 [==============================] - 131s 15ms/step - loss: 0.3106 - acc: 0.9195 - val_loss: 0.1335 - val_acc: 0.9570\n",
      "Epoch 2/4\n",
      "8995/8995 [==============================] - 129s 14ms/step - loss: 0.1444 - acc: 0.9529 - val_loss: 0.1095 - val_acc: 0.9670\n",
      "Epoch 3/4\n",
      "8995/8995 [==============================] - 128s 14ms/step - loss: 0.1329 - acc: 0.9600 - val_loss: 0.1618 - val_acc: 0.9560\n",
      "Epoch 4/4\n",
      "8995/8995 [==============================] - 129s 14ms/step - loss: 0.0799 - acc: 0.9738 - val_loss: 0.0950 - val_acc: 0.9660\n",
      "0.9985852003927519 0.9999167414451835 0.9973029987449599\n",
      "Training on fold 6/10...\n",
      "Train on 8995 samples, validate on 999 samples\n",
      "Epoch 1/4\n",
      "8995/8995 [==============================] - 132s 15ms/step - loss: 0.2932 - acc: 0.9196 - val_loss: 0.3190 - val_acc: 0.8368\n",
      "Epoch 2/4\n",
      "8995/8995 [==============================] - 130s 14ms/step - loss: 0.1504 - acc: 0.9511 - val_loss: 0.1120 - val_acc: 0.9650\n",
      "Epoch 3/4\n",
      "8995/8995 [==============================] - 135s 15ms/step - loss: 0.1248 - acc: 0.9635 - val_loss: 0.1668 - val_acc: 0.9580\n",
      "Epoch 4/4\n",
      "8995/8995 [==============================] - 134s 15ms/step - loss: 0.1109 - acc: 0.9656 - val_loss: 0.0822 - val_acc: 0.9710\n",
      "0.9978086226903509 1.0 0.9969736619580406\n",
      "Training on fold 7/10...\n",
      "Train on 8995 samples, validate on 999 samples\n",
      "Epoch 1/4\n",
      "8995/8995 [==============================] - 137s 15ms/step - loss: 0.3099 - acc: 0.9152 - val_loss: 0.0975 - val_acc: 0.9640\n",
      "Epoch 2/4\n",
      "8995/8995 [==============================] - 134s 15ms/step - loss: 0.1528 - acc: 0.9553 - val_loss: 0.0893 - val_acc: 0.9730\n",
      "Epoch 3/4\n",
      "8995/8995 [==============================] - 134s 15ms/step - loss: 0.1194 - acc: 0.9674 - val_loss: 0.1234 - val_acc: 0.9700\n",
      "Epoch 4/4\n",
      "8995/8995 [==============================] - 127s 14ms/step - loss: 0.1058 - acc: 0.9669 - val_loss: 0.0841 - val_acc: 0.9730\n",
      "0.9993439257341784 0.9993246806109327 0.9954649434341816\n",
      "Training on fold 8/10...\n",
      "Train on 8996 samples, validate on 998 samples\n",
      "Epoch 1/4\n",
      "8996/8996 [==============================] - 129s 14ms/step - loss: 0.3275 - acc: 0.9187 - val_loss: 0.0773 - val_acc: 0.9729\n",
      "Epoch 2/4\n",
      "8996/8996 [==============================] - 129s 14ms/step - loss: 0.1592 - acc: 0.9512 - val_loss: 0.2490 - val_acc: 0.9559\n",
      "Epoch 3/4\n",
      "8996/8996 [==============================] - 130s 14ms/step - loss: 0.1127 - acc: 0.9647 - val_loss: 0.1357 - val_acc: 0.9639\n",
      "Epoch 4/4\n",
      "8996/8996 [==============================] - 130s 14ms/step - loss: 0.1008 - acc: 0.9684 - val_loss: 0.1338 - val_acc: 0.9649\n",
      "0.9983640264616485 0.9998932774045065 0.9964118884609899\n",
      "Training on fold 9/10...\n",
      "Train on 8996 samples, validate on 998 samples\n",
      "Epoch 1/4\n",
      "8996/8996 [==============================] - 131s 15ms/step - loss: 0.2994 - acc: 0.9233 - val_loss: 0.1537 - val_acc: 0.9409\n",
      "Epoch 2/4\n",
      "8996/8996 [==============================] - 129s 14ms/step - loss: 0.1469 - acc: 0.9559 - val_loss: 0.0874 - val_acc: 0.9729\n",
      "Epoch 3/4\n",
      "8996/8996 [==============================] - 129s 14ms/step - loss: 0.1361 - acc: 0.9579 - val_loss: 0.3326 - val_acc: 0.8667\n",
      "Epoch 4/4\n",
      "8996/8996 [==============================] - 129s 14ms/step - loss: 0.0861 - acc: 0.9737 - val_loss: 0.1080 - val_acc: 0.9760\n",
      "0.9945378151260504 0.9997030327777571 0.9950813899586364\n",
      "Training on fold 10/10...\n",
      "Train on 8996 samples, validate on 998 samples\n",
      "Epoch 1/4\n",
      "8996/8996 [==============================] - 133s 15ms/step - loss: 0.2858 - acc: 0.9180 - val_loss: 0.1454 - val_acc: 0.9529\n",
      "Epoch 2/4\n",
      "8996/8996 [==============================] - 129s 14ms/step - loss: 0.1573 - acc: 0.9509 - val_loss: 0.2729 - val_acc: 0.9529\n",
      "Epoch 3/4\n",
      "8996/8996 [==============================] - 130s 14ms/step - loss: 0.1154 - acc: 0.9642 - val_loss: 0.0801 - val_acc: 0.9780\n",
      "Epoch 4/4\n",
      "8996/8996 [==============================] - 129s 14ms/step - loss: 0.0933 - acc: 0.9708 - val_loss: 0.1319 - val_acc: 0.9589\n",
      "0.9981003039513678 0.9999907197743049 0.9968977321352162\n",
      "Prec =  0.9967868467455115  +/- 0.0023610591058451495\n",
      "ECI =  0.9944348347353291  +/- 0.00284194477487925\n",
      "Spin =  0.9998487100151815  +/- 0.00019422907264456248\n"
     ]
    }
   ],
   "source": [
    "P = []\n",
    "E = []\n",
    "S = []\n",
    "skf = StratifiedKFold(n_splits=10,  shuffle=True)\n",
    "for index, (train_indices, val_indices) in enumerate(skf.split(X_train, Y_train)):\n",
    "    print(\"Training on fold \" + str(index+1) + \"/10...\")\n",
    "    # Generate batches from indices\n",
    "    xtrain, xval = X_train[train_indices], X_train[val_indices]\n",
    "    ytrain, yval = to_categorical(Y_train[train_indices], 3), to_categorical(Y_train[val_indices], 3)\n",
    "    # Clear model, and create it\n",
    "    model = None\n",
    "    model = create_model()\n",
    "    \n",
    "    p, s, e = train_model(model, xtrain, ytrain, xval, yval)\n",
    "    P.append(p)\n",
    "    E.append(e)\n",
    "    S.append(s)\n",
    "\n",
    "print(\"Prec = \", np.mean(P), \" +/-\", np.std(P))\n",
    "print(\"ECI = \", np.mean(E), \" +/-\", np.std(E))\n",
    "print(\"Spin = \", np.mean(S), \" +/-\", np.std(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
